{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71d00e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name - Matrikelnummer \n",
    "1) Pham, Ngoc Anh Trung - 7176267\n",
    "2) Viktor Vironski - 4330455\n",
    "3) Andy Disser - 5984875\n",
    "\n",
    "Exercise Sheet 8\n",
    "\"\"\"\n",
    "\n",
    "from random import random\n",
    "from scipy import rand\n",
    "from sklearn import cluster, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    Linear Regression Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr, l2_param=0, momentum=0):\n",
    "        \"\"\"\n",
    "        Creates a linear regression model with learning rate lr\n",
    "\n",
    "        lr : the given learning rate\n",
    "        l2_param : the L2 parameter\n",
    "        momentum : momentum of learning rate\n",
    "        \"\"\"\n",
    "\n",
    "        self.lr = lr\n",
    "        self.params_matrix = None    # matrix containing the parameters used to predict\n",
    "        self.l2_param = l2_param     # L2 regularization parameter\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Fit the data based on to MSE (mean squared error) using Gradient Descent\n",
    "\n",
    "        Inputs:\n",
    "        - X: the given data\n",
    "        - Y: the given targets\n",
    "\n",
    "        Output:\n",
    "        - the parameter matrix (used to predict)\n",
    "        \"\"\"\n",
    "\n",
    "        n = X.shape[0]      # number of trained data\n",
    "        m = X.shape[1]      # dimension of trained data / number of independent variables\n",
    "        p = Y.shape[1]      # dimension of targets / number of dependent variables\n",
    "\n",
    "    \n",
    "        # insert an additional column to X containing only 1\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        epsilons = np.full(p, 0.00001)  # Criterion for stopping the loop\n",
    "        i = 1\n",
    "\n",
    "        # Need m+1 parameters for each line (each line used to predict each output variable)\n",
    "        # Initialize all parameters as 1\n",
    "        params_matrix = np.ones((p, m+1))\n",
    "        \n",
    "        # Dummy / Initialization\n",
    "        prev_mse_matrix = np.full(p, np.infty)\n",
    "        diff = np.full(p, np.infty)\n",
    "        velocity_matrix = np.zeros((p, m+1))\n",
    "\n",
    "        while np.all(diff >= epsilons):     # Only stopping when the difference between iterations not to large\n",
    "            \n",
    "            # need to build Gradient Matrix (p x m+1):\n",
    "            # each row is an objective function concerning a predicted value y, \n",
    "            # each column is a differentiated variable\n",
    "            temp = Y + np.multiply(np.matmul(X, np.transpose(params_matrix)), -1)\n",
    "            gradient_matrix = np.divide(np.matmul(np.transpose(temp), np.multiply(X, -2)), n)\n",
    "\n",
    "            # L2 penalty term, could be a matrix in case of more than 2 output variable\n",
    "            l2_penalty = np.multiply(self.l2_param, np.apply_over_axes(np.sum, np.power(params_matrix, 2), 1))\n",
    "\n",
    "            # Compute the mean squared error for each output value and represent it in matrix\n",
    "            mse_matrix = np.divide(np.apply_over_axes(np.sum, np.power(temp, 2), 0), n) + l2_penalty\n",
    "\n",
    "            # Difference betwwen previous and current MSE matrix\n",
    "            diff = np.abs(mse_matrix-prev_mse_matrix)\n",
    "\n",
    "            # update velocity\n",
    "            velocity_matrix = np.multiply(self.lr, gradient_matrix) + np.multiply(self.momentum, velocity_matrix)\n",
    "\n",
    "            # Update point with the learning rate, gradient descending.. (with momentum)\n",
    "            params_matrix = params_matrix - velocity_matrix\n",
    "\n",
    "            # Previous MSE matrix\n",
    "            prev_mse_matrix = mse_matrix\n",
    "            i += 1\n",
    "\n",
    "        self.params_matrix = params_matrix    # Assign the parameter matrix\n",
    "        \n",
    "        return self.params_matrix\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict\n",
    "\n",
    "        Inputs:\n",
    "        - X: the given data (test data)\n",
    "\n",
    "        Output:\n",
    "        - predicted value, store in a matrix form\n",
    "        \"\"\"\n",
    "\n",
    "        # insert an additional column to X containing only 1\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        # Predict\n",
    "        predicted_matrix = np.matmul(X, np.transpose(self.params_matrix))\n",
    "\n",
    "        return predicted_matrix\n",
    "\n",
    "\n",
    "def cross_validation(train_data, train_targets, l2_param):\n",
    "    \"\"\"\n",
    "    5-fold cross validation for L2 parameter\n",
    "\n",
    "    Inputs:\n",
    "    - train_data: the given train data\n",
    "    - train_targets: the given train target\n",
    "    - l2_param: the given L2 parameter\n",
    "\n",
    "    Output:\n",
    "    - score/loss value of this L2 parameter\n",
    "    \"\"\"\n",
    "\n",
    "    indices = np.arange(train_data.shape[0])\n",
    "    i, j =0, 0\n",
    "    \n",
    "    # average MSE of each iteration\n",
    "    avg_mse = np.zeros(5)\n",
    "    \n",
    "    # Split in 5 chunks and take in each iteration a chunk as test data\n",
    "    while i < 10:\n",
    "        split_filter = np.logical_and(indices >= i*10, indices < (i+2)*10)\n",
    "        \n",
    "        cv_test_indices = indices[split_filter]\n",
    "        cv_train_indices = indices[np.logical_not(split_filter)]\n",
    "\n",
    "        cv_train = np.take_along_axis(train_data, cv_train_indices[:, np.newaxis], 0)\n",
    "        cv_train_targets = np.take_along_axis(train_targets, cv_train_indices[:, np.newaxis], 0)\n",
    "        \n",
    "        cv_test = np.take_along_axis(train_data, cv_test_indices[:, np.newaxis], 0)\n",
    "        cv_test_targets = np.take_along_axis(train_targets, cv_test_indices[:, np.newaxis], 0)\n",
    "\n",
    "        myModel = LinearRegression(0.01, l2_param)\n",
    "        myModel.fit(cv_train, cv_train_targets)\n",
    "        predicted_matrix = myModel.predict(cv_test)\n",
    "        \n",
    "        # Take the uniform average over all mean squared errors (in case there are \n",
    "        # multiple output value) as lost score\n",
    "        avg_mse[j] = np.average(np.divide(np.apply_over_axes(np.sum, \\\n",
    "            np.power(np.abs(cv_test_targets-predicted_matrix), 2), 0), cv_test.shape[0]).reshape(cv_test_targets.shape[1]))\n",
    "        \n",
    "        i += 2\n",
    "        j += 1\n",
    "\n",
    "\n",
    "    return np.average(avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd77e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of needed iterations: 1242\n",
      "MSE of petal length and petal width respectively:\n",
      " [[0.51254037 0.16704454]]\n"
     ]
    }
   ],
   "source": [
    "# Import and access  data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# ==================== Exercise 1a ============================\n",
    "\n",
    "# Create permutation of 0,1,..,149\n",
    "permutation = np.random.permutation(np.arange(150))\n",
    "train_filter = permutation < 100\n",
    "test_filter = permutation >= 100 \n",
    "\n",
    "# Split the data, 100 samples for training, 50 samples for testing\n",
    "train_data = iris.data[train_filter][:, :2]\n",
    "test_data = iris.data[test_filter][:, :2]\n",
    "\n",
    "# The respective targets (petal length and petal width)\n",
    "train_targets = iris.data[train_filter][:, 2:]\n",
    "test_targets = iris.data[test_filter][:, 2:]\n",
    "\n",
    "# Initialize the model and fit the data\n",
    "myModel = LinearRegression(0.01)\n",
    "myModel.fit(train_data, train_targets)\n",
    "# Predict the test data\n",
    "\n",
    "predicted_matrix = myModel.predict(test_data)\n",
    "\n",
    "# Compute the mean squared error for test data\n",
    "mse_matrix = np.divide(np.apply_over_axes(np.sum, \\\n",
    "    np.power(np.abs(test_targets-predicted_matrix), 2), 0), test_data.shape[0])\n",
    "\n",
    "print(\"MSE of petal length and petal width respectively:\\n\", mse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6edf506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of needed iterations: 145\n",
      "MSE of petal length and petal width respectively (L2 parameter of 0.3):\n",
      " [[0.96619854 0.31542583]]\n",
      "Number of needed iterations: 170\n",
      "Number of needed iterations: 136\n",
      "Number of needed iterations: 123\n",
      "Number of needed iterations: 121\n",
      "Number of needed iterations: 126\n",
      "Number of needed iterations: 122\n",
      "Number of needed iterations: 189\n",
      "Number of needed iterations: 169\n",
      "Number of needed iterations: 83\n",
      "Number of needed iterations: 86\n",
      "Number of needed iterations: 188\n",
      "Number of needed iterations: 206\n",
      "Number of needed iterations: 169\n",
      "Number of needed iterations: 172\n",
      "Number of needed iterations: 70\n",
      "Number of needed iterations: 162\n",
      "Number of needed iterations: 182\n",
      "Number of needed iterations: 148\n",
      "Number of needed iterations: 152\n",
      "Number of needed iterations: 167\n",
      "Number of needed iterations: 145\n",
      "Number of needed iterations: 63\n",
      "Number of needed iterations: 134\n",
      "Number of needed iterations: 138\n",
      "Number of needed iterations: 109\n",
      "Number of needed iterations: 83\n",
      "Number of needed iterations: 59\n",
      "Number of needed iterations: 221\n",
      "Number of needed iterations: 228\n",
      "Number of needed iterations: 140\n",
      "Number of needed iterations: 124\n",
      "Number of needed iterations: 146\n",
      "Number of needed iterations: 116\n",
      "Number of needed iterations: 212\n",
      "Number of needed iterations: 132\n",
      "Number of needed iterations: 203\n",
      "Number of needed iterations: 54\n",
      "Number of needed iterations: 110\n",
      "Number of needed iterations: 200\n",
      "Number of needed iterations: 125\n",
      "Number of needed iterations: 197\n",
      "Number of needed iterations: 134\n",
      "Number of needed iterations: 105\n",
      "Number of needed iterations: 488\n",
      "Number of needed iterations: 120\n",
      "Number of needed iterations: 192\n",
      "Number of needed iterations: 216\n",
      "Number of needed iterations: 572\n",
      "Number of needed iterations: 181\n",
      "Number of needed iterations: 204\n",
      "The best L2 parameter sofar is  1.0  with the loss value of  0.7879574971478238\n"
     ]
    }
   ],
   "source": [
    "# ==================== Exercise 1b ============================\n",
    "\n",
    "# Initialize the model and fit the data but this time with L2 parameter of 0.3\n",
    "myModel = LinearRegression(0.01, 0.3)\n",
    "myModel.fit(train_data, train_targets)\n",
    "\n",
    "# Predict the test data\n",
    "predicted_matrix = myModel.predict(test_data)\n",
    "\n",
    "# Compute the mean squared error for test data\n",
    "mse_matrix = np.divide(np.apply_over_axes(np.sum, \\\n",
    "    np.power(np.abs(test_targets-predicted_matrix), 2), 0), test_data.shape[0])\n",
    "\n",
    "print(\"MSE of petal length and petal width respectively (L2 parameter of 0.3):\\n\", mse_matrix)\n",
    "\n",
    "# search in 10 different values of L2 parameter to find out which \n",
    "# perform best using cross validation for each of them\n",
    "reg_params = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Vectorize the function and compute the loss of each parameter\n",
    "vec_cross_validation = np.vectorize(cross_validation, signature='(m,n),(m,n),() -> ()')\n",
    "results = vec_cross_validation(train_data, train_targets, reg_params)\n",
    "\n",
    "print(\"The best L2 parameter sofar is \", reg_params[np.argmin(results)], \" with the loss value of \", np.min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdecb92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of needed iterations: 118\n",
      "MSE of petal length and petal width respectively (momentum of 0.9):\n",
      " [[0.51604085 0.16933735]]\n"
     ]
    }
   ],
   "source": [
    "# ==================== Exercise 1c ============================\n",
    "\n",
    "# Initialize the model and fit the data but this time with momentum of 0.9\n",
    "myModel = LinearRegression(0.01, 0, 0.9)\n",
    "myModel.fit(train_data, train_targets)\n",
    "\n",
    "# Predict the test data\n",
    "predicted_matrix = myModel.predict(test_data)\n",
    "\n",
    "# Compute the mean squared error for test data\n",
    "mse_matrix = np.divide(np.apply_over_axes(np.sum, \\\n",
    "    np.power(np.abs(test_targets-predicted_matrix), 2), 0), test_data.shape[0])\n",
    "\n",
    "print(\"MSE of petal length and petal width respectively (momentum of 0.9):\\n\", mse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf175af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
