{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72808464",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Name - Matrikelnummer \n",
    "1) Pham, Ngoc Anh Trung - 7176267\n",
    "2) Viktor Vironski - 4330455\n",
    "3) Andy Disser - 5984875\n",
    "\n",
    "Exercise Sheet 5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbfdc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from sklearn import cluster, datasets\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "910ca031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda1f3b",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "423dee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmargin(data, labels, supportvec):\n",
    "    \"\"\"\n",
    "    Compute the soft margin score\n",
    "\n",
    "    Inputs:\n",
    "    - data: the given data\n",
    "    - labels: the given labels\n",
    "    - supportvec: the given indices of support vectors\n",
    "\n",
    "    Output:\n",
    "    - the soft margin score ( # misclassification * (-margin) )\n",
    "    \"\"\"\n",
    "\n",
    "    # Left and right support vectors\n",
    "    left = data[supportvec[0]]\n",
    "    right = data[supportvec[1]]\n",
    "\n",
    "    # Compute threshold\n",
    "    th = np.abs(np.divide(left+right,2))\n",
    "\n",
    "    # Compute margin\n",
    "    margin = np.abs(left-th)\n",
    "\n",
    "    # Miss classification for label 1 when they are on the right side of the threshold\n",
    "    missclassification1 = np.logical_and((data-th > 0), (labels == 0))\n",
    "    # Miss classification for label 2 when they are on the left side of the threshold\n",
    "    missclassification2 = np.logical_and((data-th < 0), (np.logical_or(labels == 1,\\\n",
    "         labels == 2)))\n",
    "\n",
    "    # Miss classified when only one of the two criterion above is satisfied\n",
    "    missclassification = np.logical_xor(missclassification1, missclassification2)\n",
    "\n",
    "    # The number of missclassified points\n",
    "    num_of_missclass = np.size(data[missclassification])\n",
    "\n",
    "    # Weight each of the miss classified with negative margin and\n",
    "    # return the sum as soft margin score\n",
    "    return np.multiply(num_of_missclass, (-margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "229d0fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import and access the data\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris['data']\n",
    "\n",
    "n = iris_data.shape[0]\n",
    "\n",
    "# Extract the petal widths\n",
    "data = iris_data[:, 3]\n",
    "\n",
    "# Create permutation of 0,1,..,149\n",
    "permutation = np.random.permutation(np.arange(150))\n",
    "train_filter = permutation < 100\n",
    "test_filter = permutation >= 100\n",
    "\n",
    "# Split the data, 100 samples for training, 50 samples for testing\n",
    "train_data = data[train_filter]\n",
    "test_data = data[test_filter]\n",
    "\n",
    "# The respective labels\n",
    "train_target = iris.target[train_filter]\n",
    "test_target = iris.target[test_filter]\n",
    "\n",
    "# ============= 1b =================================\n",
    "\n",
    "# Repeat 20 times\n",
    "i = 0\n",
    "best_margin_score = -np.inf\n",
    "best_supp_vec_indices = np.zeros(2)\n",
    "# The indices of the train data\n",
    "indices = np.arange(100)\n",
    "while i < 20:\n",
    "\n",
    "    # Pick 2 random point, one from 1 class and the other from other class\n",
    "    supp_vec_left = np.random.choice(indices[train_target == 0], 1, replace=False)\n",
    "    supp_vec_right = np.random.choice(indices[np.logical_or(train_target == 1, train_target == 2)], 1, replace=False)\n",
    "\n",
    "    supp_vec_indices = np.array([supp_vec_left, supp_vec_right])\n",
    "\n",
    "    # Compute score\n",
    "    score = softmargin(train_data, train_target, supp_vec_indices)\n",
    "\n",
    "    # Compare score\n",
    "    if score > best_margin_score:\n",
    "        best_margin_score = score\n",
    "        best_supp_vec_indices = supp_vec_indices\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# ============ 1b Test the data ========================================\n",
    "\n",
    "# Compute threshold\n",
    "th = np.divide(train_data[best_supp_vec_indices[0]]+train_data[best_supp_vec_indices[1]], 2)\n",
    "\n",
    "# filter the positions that the algorithm predicted the point belongs to class/label 1\n",
    "predicted_label1 = th-test_data > 0\n",
    "\n",
    "# filter the positions that the algorithm predicted the point belongs to class/label 2\n",
    "predicted_label2 = th-test_data <= 0\n",
    "\n",
    "truth_label1 = test_target == 0\n",
    "truth_label2 = np.logical_or(test_target == 1, test_target == 2)\n",
    "\n",
    "correctly_classified_1 = np.logical_and(predicted_label1, truth_label1)\n",
    "correctly_classified_2 = np.logical_and(predicted_label2, truth_label2)\n",
    "\n",
    "correct_classified_test_data = test_data[np.logical_or(correctly_classified_1, correctly_classified_2)]\n",
    "\n",
    "print(\"Accuracy:\", np.divide(np.size(correct_classified_test_data), np.size(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25062915",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68c2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e383ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb39c60",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ae4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers from 1 to 150 randomly shuffled\n",
    "random_inidices = np.random.choice(150,size=150, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80de8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the first 105 random indicies for training and the rest for testing\n",
    "training_inices, test_indices = random_inidices[:105], random_inidices[105:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361a005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data from the randomly picked indicies\n",
    "training_data = np.zeros((105,4))\n",
    "for num, index in enumerate(training_inices):\n",
    "    training_data[num,:] = data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db53d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training targets from the randomly picked indicies\n",
    "training_target = np.zeros((105))\n",
    "for num, index in enumerate(training_inices):\n",
    "    training_target[num] = iris.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3cd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data from the randomly picked inidicies\n",
    "test_data = np.zeros((45,4))\n",
    "for num, index in enumerate(test_indices):\n",
    "    test_data[num,:] = data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f0a9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test targets from the randomly picked inidicies\n",
    "test_target = np.zeros(45)\n",
    "for num, index in enumerate(test_indices):\n",
    "    test_target[num] = iris.target[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf507886",
   "metadata": {},
   "source": [
    "# 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85106cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1, 10], 'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15609a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the C-gamma combinations is shown in the following matrix (C,gamma):\n",
      "\n",
      "[[0.22857143 0.22857143 0.22857143 0.22857143]\n",
      " [0.22857143 0.22857143 0.22857143 0.22857143]\n",
      " [0.37142857 0.80952381 0.93333333 0.24761905]\n",
      " [0.8952381  0.95238095 0.95238095 0.92380952]\n",
      " [0.96190476 0.98095238 0.94285714 0.92380952]]\n",
      "\n",
      "The highest accuracy is 0.980952380952381. \n",
      "It was achieved with (C,gamma) = (10, 0.1)\n"
     ]
    }
   ],
   "source": [
    "accuracy_matrix = np.zeros((len(param_grid[\"C\"]),len(param_grid[\"gamma\"])))\n",
    "\n",
    "# iterate over all C-gamma combinations and all folds\n",
    "for c_index, c in enumerate(param_grid[\"C\"]):  \n",
    "    for g_index, gamma in enumerate(param_grid[\"gamma\"]):\n",
    "        \n",
    "        # array for the accuracies in fold i\n",
    "        acc_folds = np.zeros(5)\n",
    "        \n",
    "        # split the data into 5 subarrays\n",
    "        fold_data_arrays = np.split(training_data, 5)\n",
    "        fold_target_arrays = np.split(training_target, 5)\n",
    "        \n",
    "        for fold_i in range(5):\n",
    "            \n",
    "            #copy folds array to make no changes at the original list of arrays\n",
    "            fold_i_data = fold_data_arrays.copy()\n",
    "            fold_i_target = fold_target_arrays.copy()\n",
    "            \n",
    "            #test data for the i-th fold\n",
    "            fold_i_test_d = fold_i_data.pop(fold_i)\n",
    "            fold_i_test_t = fold_i_target.pop(fold_i)\n",
    "            \n",
    "            # training data for the i-th fold\n",
    "            fold_i_training_d = np.concatenate(fold_i_data)\n",
    "            fold_i_training_t = np.concatenate(fold_i_target)\n",
    "            \n",
    "            # calculate the pobability\n",
    "            acc = SVC(C=c, gamma=gamma)\n",
    "            acc.fit(fold_i_training_d, fold_i_training_t)\n",
    "            acc_folds[fold_i] = acc.score(fold_i_test_d, fold_i_test_t)\n",
    "        \n",
    "        # calculate the average accuracy\n",
    "        accuracy_matrix[c_index, g_index] = np.mean(acc_folds)\n",
    "\n",
    "# best values for C and gamma\n",
    "best_C = param_grid[\"C\"][np.argmax(accuracy_matrix)//4]\n",
    "best_gamma = param_grid[\"gamma\"][np.argmax(accuracy_matrix)%4]\n",
    "\n",
    "print(f\"The accuracy of the C-gamma combinations is shown in the following matrix (C,gamma):\\n\\n\\\n",
    "{accuracy_matrix}\")\n",
    "print()\n",
    "print(f\"The highest accuracy is {np.amax(accuracy_matrix)}. \\n\\\n",
    "It was achieved with (C,gamma) = {(best_C,best_gamma)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f77944",
   "metadata": {},
   "source": [
    "# train the whole trainig data with the optimal parameters from cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b19a0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = SVC(C=best_C,gamma=best_gamma, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "918772fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(training_data, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff5c951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(test_data, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
