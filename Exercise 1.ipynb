{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6100eb",
   "metadata": {},
   "source": [
    "# Machine Learning 1 - Exercise Sheet 1\n",
    "\n",
    "## Viktor Vironski (4330455), Andy Disser (5984875), Trung (Matrikelnummer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7882956",
   "metadata": {},
   "source": [
    "### Exercise 1. Min-Max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee743ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) The first five data point of the feature vectors scaled data set are: \n",
      "\n",
      "[[1.         0.67346939 0.24489796 0.        ]]\n",
      "[[1.         0.59574468 0.25531915 0.        ]]\n",
      "[[1.         0.66666667 0.24444444 0.        ]]\n",
      "[[1.         0.65909091 0.29545455 0.        ]]\n",
      "[[1.         0.70833333 0.25       0.        ]]\n",
      "\n",
      "\n",
      "b) The first five data point of the fully scaled data set are: \n",
      "\n",
      "[[0.64102564 0.43589744 0.16666667 0.01282051]]\n",
      "[[0.61538462 0.37179487 0.16666667 0.01282051]]\n",
      "[[0.58974359 0.3974359  0.15384615 0.01282051]]\n",
      "[[0.57692308 0.38461538 0.17948718 0.01282051]]\n",
      "[[0.62820513 0.44871795 0.16666667 0.01282051]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# implement Min-Max Normalization Function for range 0 to 1\n",
    "\n",
    "def min_max_scale( data: list, min_range = 0, max_range = 1):\n",
    "    \n",
    "    # copy existing data to a new workable instance\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    # calculate global minimum and global maximum of the data\n",
    "    min_value = np.matrix(new_data).min()\n",
    "    max_value = np.matrix(new_data).max()\n",
    "    \n",
    "    # normalize data using formula x_scaled = (x - min_value)/(max_value - min_value)\n",
    "    new_data -= min_value\n",
    "    new_data *= ( 1 / (max_value - min_value))\n",
    "    \n",
    "    # return global minimum, glubal maximum and the normalized data set\n",
    "    return( new_data, min_value, max_value)\n",
    "\n",
    "\n",
    "# set iris to a numpy matrix from the iris data\n",
    "iris = np.matrix(datasets.load_iris().data)\n",
    "\n",
    "### a) scale all features seperatly\n",
    "# initial attempt at transposing the data matrix did not work as planed, therefore loop implementation\n",
    "\n",
    "iris_feature_vectors_normed = []\n",
    "\n",
    "# for all rows in the iris data set apply Min-Max Normalization\n",
    "for i in range(0, len(iris.data)):\n",
    "    iris_feature_vectors_normed.append(min_max_scale(iris[i],0, 1))\n",
    "\n",
    "# print first five data points of the feature normed iris data set\n",
    "print('a) The first five data point of the feature vectors scaled data set are:', '\\n')\n",
    "for j in range (0, 5):\n",
    "    print(iris_feature_vectors_normed[j][0])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "### b) scale the full dataset\n",
    "\n",
    "# apply Min-Max Normalization to the full data set\n",
    "iris_full_dataset_normed = min_max_scale(iris, 0, 1)\n",
    "\n",
    "# print first five data points of the fully scaled data set\n",
    "print('b) The first five data point of the fully scaled data set are:', '\\n')\n",
    "for i in range (0, 5):\n",
    "    print(iris_full_dataset_normed[0][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b1adf",
   "metadata": {},
   "source": [
    "### Exercise 2. Z-Score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719397b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the original dataset by column\n",
    "#sepal_length_norm = min_max_scale(iris.data[:, 0:1], 0, 1)\n",
    "#sepal_width_norm = min_max_scale(iris.data[:, 1:2], 0, 1)\n",
    "#petal_length_norm = min_max_scale(iris.data[:, 2:3], 0, 1)\n",
    "#petal_width_norm = min_max_scale(iris.data[:, 3:4], 0, 1)\n",
    "\n",
    "#print('Min-max normalization of the iris dataset for sepal length, using feature minimum', sepal_length_norm[0],\n",
    "#      'and feature maximum', sepal_length_norm[1], 'is:')\n",
    "#print(sepal_length_norm[2], '\\n')\n",
    "#\n",
    "#print('Min-max normalization of the iris dataset for sepal length, using feature minimum', sepal_width_norm[0],\n",
    "#      'and feature maximum', sepal_width_norm[1], 'is:')\n",
    "#print(sepal_width_norm[2], '\\n')\n",
    "#\n",
    "#print('Min-max normalization of the iris dataset for sepal length, using feature minimum', petal_length_norm[0],\n",
    "#      'and feature maximum', petal_length_norm[1], 'is:')\n",
    "#print(petal_length_norm[2], '\\n')\n",
    "#\n",
    "#print('Min-max normalization of the iris dataset for sepal length, using feature minimum', petal_width_norm[0],\n",
    "#      'and feature maximum', petal_width_norm[1], 'is:')\n",
    "#print(petal_width_norm[2], '\\n')\n",
    "\n",
    "# b) scale the full dataset\n",
    "\n",
    "#A = iris.data[:, :1]\n",
    "#B = iris.data[:, 1:2]\n",
    "#C = iris.data[:, 2:3]\n",
    "#D = iris.data[:, 3:4]\n",
    "\n",
    "#print(A)\n",
    "#print(B)\n",
    "#print(C)\n",
    "#print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aab536",
   "metadata": {},
   "source": [
    "### Exercise 3. Plotting I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252db817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
